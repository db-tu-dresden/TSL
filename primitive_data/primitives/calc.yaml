---
name: "calc"
description: "This file contains arithmetic primitives."
...
---
primitive_name: "add"
brief_description: "Adds two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the addition."
testing: #optional
  - test_name: "zero_cornercase"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = set1<Vec>( 0 );
        auto elements = loadu<Vec>(&test_data_ptr[i]);
        vec = add<Vec>(vec, elements);
        storeu<Vec>( test_result_ptr, vec );
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "running_sum_w_epsilon"
    requires: [ "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - 2*Vec::vector_element_count(); i+=2*Vec::vector_element_count()) {
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j]+reference_data_ptr[j+Vec::vector_element_count()];
        }
        auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
        auto elements_vec2 = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
        auto vec = add<Vec>(elements_vec1, elements_vec2);
        storeu<Vec>( test_result_ptr, vec );
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#CUDA
  - target_extension: "cuda"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ["cuda"]
    vector_length_agnostic: True
    implementation: |
      typename Vec::register_type vec_c;
      size_t element_count = VectorSize / (sizeof({{ ctype }}) * 8);
      constexpr auto add = +[]({{ ctype }} a, {{ ctype }} b) { return a + b; };
      return launch_elemenwise_op<typename Vec::register_type, add>(vec_a, vec_b, VectorSize);
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t"]
    lscpu_flags: ['avx512f', 'avx512bw']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed addition."
    implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['sse2']
    specialization_comment: "Signed addition."
    implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vaddq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: []
    implementation: "return vec_a + vec_b;"
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] + vec_b[i];
      }
      return result;
...
---
primitive_name: "sub"
brief_description: "Subtracts two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the subtraction."
testing: #optional
  - test_name: "zero_cornercase"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j];
          }
          auto vec = set1<Vec>( 0 );
          auto elements = loadu<Vec>(&test_data_ptr[i]);
          vec = sub<Vec>(elements, vec);
          storeu<Vec>( test_result_ptr, vec );
          test_helper.synchronize();
          allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "running_sum_w_epsilon"
    requires: ["loadu", "store"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - 2*Vec::vector_element_count(); i+=2*Vec::vector_element_count()) {
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j]-reference_data_ptr[j+Vec::vector_element_count()];
          }
          auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
          auto elements_vec2 = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
          auto vec = sub<Vec>(elements_vec1, elements_vec2);
          storeu<Vec>( test_result_ptr, vec );
          test_helper.synchronize();
          allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#CUDA
  - target_extension: "cuda"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ["cuda"]
    vector_length_agnostic: True
    implementation: |
      typename Vec::register_type vec_c;
      size_t element_count = VectorSize / (sizeof({{ ctype }}) * 8);
      constexpr auto add = +[]({{ ctype }} a, {{ ctype }} b) { return a - b; };
      return launch_elemenwise_op<typename Vec::register_type, add>(vec_a, vec_b, VectorSize);
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t"]
    lscpu_flags: ['avx512f', 'avx512bw']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed addition."
    implementation: "return _mm256_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['sse2']
    specialization_comment: "Signed addition."
    implementation: "return _mm_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vsubq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: []
    implementation: "return vec_a - vec_b;"
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] - vec_b[i];
      }
      return result;
---
primitive_name: "add"
functor_name: "mask_add"
brief_description: "Adds two vector registers, depending on a mask: result[*] = (m[*])? vec_a[*]+vec_b[*] : vec_a[*]."
parameters:
  - ctype: "const typename Vec::mask_type"
    name: "mask"
    description: "Vector mask register indicating which elements should be added."
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the addition."
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mask_add_{{ intrin_tp_full[ctype] }}(vec_a, mask, vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm256_and_si256(vec_b, mask));"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, _mm256_and_{{ intrin_tp_full[ctype] }}(vec_b, mask));"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm_and_si128(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_add_ps(vec_a, _mm_and_ps(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_pd(vec_a, _mm_and_pd(vec_b, mask));"
---
primitive_name: "mul"
brief_description: "Multiplies two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the multiplication."
testing:
  - requires: ["loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        std::size_t element_count = 1024;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        for(std::size_t i = 0; i < element_count - (2*Vec::vector_element_count()); i+=(2*Vec::vector_element_count())) {
          std::size_t j = i;
          for(; j < i + Vec::vector_element_count(); ++j) {
              reference_result_ptr[j-i] = reference_data_ptr[j];
          }
          for(; j < i + (2*Vec::vector_element_count()); ++j) {
              reference_result_ptr[j-(i+Vec::vector_element_count())] *= reference_data_ptr[j];
          }
          auto vec_a = loadu<Vec>(&test_data_ptr[i]);
          auto vec_b = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
          auto vec_result = mul<Vec>(vec_a, vec_b);
          storeu<Vec>(test_result_ptr, vec_result);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint16_t"]
    lscpu_flags: ["avx512bw"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["int16_t"]
    lscpu_flags: ["avx512bw"]
    implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi32(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi64(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
      _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi32(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi64(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_mul_ps(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_mul_pd(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["sse2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi16(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse4_1"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi32(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi64(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vmulq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
  - target_extension: "neon"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: [ 'neon' ]
    is_native: False
    implementation: |
      //Found this on stackoverflow. This seems like an overkill. Maybe an extract and scalar multiply would do the trick more efficient.
      //@todo: benchmark this.
      const auto ac = vmovn_{{ intrin_tp[ctype][0] }}64(vec_a);
      const auto pr = vmovn_{{ intrin_tp[ctype][0] }}64(vec_b);
      const auto hi = vmulq_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_b), vrev64q_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_a)));
      return vmlal_{{ intrin_tp[ctype][0] }}32(vshlq_n_{{ intrin_tp[ctype][0] }}64(vpaddlq_{{ intrin_tp[ctype][0] }}32(hi), 32), ac, pr);
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: "return vec_a * vec_b;"
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] * vec_b[i];
      }
      return result;
...
---
primitive_name: "hadd"
brief_description: "Reduces the elements to a sum."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "value"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
testing:
  - requires: ["set1"]
    includes: ["<cstddef>", "<algorithm>", "<limits>"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{1, false};
      bool allOk = true;
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      const std::size_t limit = std::min( (size_t) 4096, (size_t) std::numeric_limits<T>::max() / Vec::vector_element_count() );
      for(std::size_t i = 0; i < limit; ++i) {
        *reference_result_ptr =  Vec::vector_element_count() * i;
        auto vec = set1<Vec>(i);
        *test_result_ptr = hadd<Vec>(vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - FPGA
  - target_extension: "oneAPIfpga"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      if constexpr(Vec::vector_element_count() < 256) {
        return reducer::apply<typename Vec::base_type, Vec::vector_element_count(), functors::add<simd<typename Vec::base_type, scalar>, Idof>>(value);
      } else {
        {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
        {{ helpers.tree_like_reduce("Vec", "result_vec", "value", "+") }}
        return result_vec[Vec::vector_element_count()-2];        
      }
  - target_extension: "oneAPIfpgaRTL"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    specialization_comment: "This is for testing reasons only and does *not* use any RTL codes."
    implementation: |
      if constexpr(Vec::vector_element_count() < 256) {
        return reducer::apply<typename Vec::base_type, Vec::vector_element_count(), functors::add<simd<typename Vec::base_type, scalar>, Idof>>(value);
      } else {
        {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
        {{ helpers.tree_like_reduce("Vec", "result_vec", "value", "+") }}
        return result_vec[Vec::vector_element_count()-2];        
      }
  # - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
  #   ctype: ["uint64_t", "int64_t", "double"]
  #   lscpu_flags: ["oneAPIfpgaDev"]
  #   vector_length_agnostic: True
  #   implementation: |
  #     using T = typename Vec::base_type;
  #     T result = 0; //initialize the result
  #     #pragma unroll
  #     for(int i = 0; i < Vec::vector_element_count(); i+=16) {
  #       T add_1_1 = value[i  ] + value[i+1];
  #       T add_1_2 = value[i+2] + value[i+3];
  #       T add_1_3 = value[i+4] + value[i+5];
  #       T add_1_4 = value[i+6] + value[i+7];

  #       T add_2_1 = add_1_1 + add_1_2;
  #       T add_2_2 = add_1_3 + add_1_4;

  #       result += add_2_1 + add_2_2;
  #     }
  #     return result;
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
    implementation: "return _mm512_reduce_add_{{ intrin_tp_full[ctype] }}(value);"
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Signed Addition. Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
    implementation: "return _mm512_reduce_add_epi{{ intrin_tp[ctype][1] }}(value);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm512_store_si512(reinterpret_cast<void*>(buffer.data()), value);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          result += buffer[i];
      }
      return result;
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["double"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      //https://stackoverflow.com/questions/49941645/get-sum-of-values-stored-in-m256d-with-sse-avx
      __m128d vlow  = _mm256_castpd256_pd128(value);
      __m128d vhigh = _mm256_extractf128_pd(value, 1);
      vlow  = _mm_add_pd(vlow, vhigh);
      __m128d high64 = _mm_unpackhi_pd(vlow, vlow);
      return  _mm_cvtsd_f64(_mm_add_sd(vlow, high64));
  - target_extension: "avx2"
    ctype: ["float"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse", "sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      __m128 vlow  = _mm256_castps256_ps128(value);
      __m128 vhigh = _mm256_extractf128_ps(value, 1);
      vlow = _mm_add_ps(vlow, vhigh);
      __m128 res = _mm_hadd_ps(vlow, vlow);
      return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
  - target_extension: "avx2"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      __m128i vlow = _mm256_castsi256_si128(value);
      __m128i vhigh = _mm256_extractf128_si256(value, 1);
      vlow = _mm_add_epi64(vlow, vhigh);
      __m128i high64 = _mm_unpackhi_epi64(vlow, vlow);
      return _mm_cvtsi128_si64(_mm_add_epi64(vlow, high64));
  - target_extension: "avx2"
    ctype: ["uint32_t", "int32_t"]
    specialization_comment: "Signed Addition. This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      __m128i vlow = _mm256_castsi256_si128(value);
      __m128i vhigh = _mm256_extractf128_si256(value, 1);
      vlow = _mm_add_epi32(vlow, vhigh);
      __m128i res = _mm_hadd_epi32(vlow, vlow);
      return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), value);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        result += buffer[i];
      }
      return result;
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    is_native: False
    implementation: |
      return _mm_cvtsd_f64(value) + _mm_cvtsd_f64(_mm_castsi128_pd(_mm_bsrli_si128(_mm_castpd_si128(value),sizeof(double))));
  - target_extension: "sse"
    ctype: ["float"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse", "sse2", "ssse3"]
    is_native: False
    implementation: |
      auto res = _mm_hadd_ps(value, value);
      return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
  - target_extension: "sse"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      return _mm_cvtsi128_si64(value) + _mm_cvtsi128_si64(_mm_bsrli_si128(value,sizeof(uint64_t)));
  - target_extension: "sse"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse2", "ssse3", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      auto res = _mm_hadd_epi32(value, value);
      return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm_store_si128(reinterpret_cast<__m128i *>(buffer.data()), value);
      for  (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            result += buffer[i];
      }
      return result;
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vaddvq_{{ intrin_tp_full[ctype] }}( value );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: "return value;"
...
---
primitive_name: "min"
brief_description: "compares the values of 2 vectors and returns a vector with the minimum of each corrisponding values"
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector"
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector"
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the comparison"
testing:
  - test_name: "min_general_case"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        const std::size_t element_count = 2048;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(0);
        for(std::size_t i = 0; i < element_count / 2; i += Vec::vector_element_count()){
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); j++){
            if(reference_data_ptr[j] < reference_data_ptr[j + (element_count/2)]){
              reference_result_ptr[tester_idx++] = reference_data_ptr[j];
            } else {
              reference_result_ptr[tester_idx++] = reference_data_ptr[j + (element_count/2)];
            }
          }
          auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
          auto elements_vec2 = loadu<Vec>(&test_data_ptr[i + (element_count/2)]);
          vec = min<Vec>(elements_vec1, elements_vec2);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
  - test_name: "min_zero_case"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        std::size_t element_count = 1024;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        for(std::size_t i = 0; i < element_count; i += Vec::vector_element_count()){
          auto vec = set1<Vec>(0);
          storeu<Vec>(reference_result_ptr, vec);
          auto elements_vec = loadu<Vec>(&test_data_ptr[i]);
          vec = min<Vec>(vec, elements_vec);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed Min"
    implementation: "return _mm512_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t" ]
    lscpu_flags: ['avx512bw']
    specialization_comment: "Signed Min"
    implementation: "return _mm512_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed & unsigned Min"
    implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["int64_t", "uint64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Takes a mask to check the smaller value of each Vector and takes that mask to get the smaller value of either vec_a or vec_b"
    is_native: False
    implementation: |
      typename Vec::register_type mask = _mm256_cmpgt_epi64(vec_a, vec_b);
      return _mm256_blendv_epi8(vec_a, vec_b, mask);
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int16_t", "double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["int8_t", "uint16_t", "uint32_t", "int32_t"]
    lscpu_flags: ['sse4_1']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
#ARM - NEON
  - target_extension: "neon"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "int8_t", "int32_t", "double", "float" ]
    lscpu_flags: ['neon']
    implementation: "return vminq_{{intrin_tp_full[ctype]}}(vec_a, vec_b);" #What about 64-Bit
#SCALAR
  - target_extension: "scalar"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: []
    includes: []
    implementation: |
        if (vec_a > vec_b) return vec_b;
        return vec_a;
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] < vec_b[i] ? vec_a[i] : vec_b[i];
      }
      return result;
...
---
primitive_name: "div"
brief_description: "Divides two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the division."
testing:
  - test_name: "vec_with_itself"
    requires: ["loadu", "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        auto vec = set1<Vec>(1);
        storeu<Vec>(reference_result_ptr, vec);
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        vec = div<Vec>(vec_a, vec_a);
        storeu<Vec>(test_result_ptr, vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "vec_with_one"
    requires: ["loadu", "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j=i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = set1<Vec>(1);
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        auto vec_result = div<Vec>(vec_a, vec);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
          _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
          _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
          for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            buffer_a[i] /= buffer_b[i];
          }
          return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['avx']
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] /= buffer_b[i];
        }
        return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float", "double"]
    lscpu_flags: ['sse']
    implementation: "return _mm_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['sse2']
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] /= buffer_b[i];
        }
        return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON - TODO: Cant check if Correct
  - target_extension: "neon"
    ctype: ["float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vdivq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
  - target_extension: "neon"
    ctype: ["uint64_t"]
    lscpu_flags: ['neon']
    implementation: |
      typename Vec::register_type recipocal_estimate = vshrq_n_u64(vdupq_n_u64(0xFFFFFFFFFFFFFFFF), vclzq_u64(vec_b));
      recipocal_estimate = vmulq_u64(recipocal_estimate, vsubq_u64(vdupq_n_u64(2), vmulq_u64(vec_b, recipocal_estimate)));
      typename Vec::register_type temp = vmulq_u64(vec_a, recipocal_estimate);
      temp = vqrdmulhq_u64(temp, vec_b);
      return temp;
  - target_extension: "neon"
    ctype: ["uint32_t"]
    lscpu_flags: ['neon']
    is_native: False
    implementation: |
      typename Vec::register_type temp = vrecpe_{{intrin_tp_full[ctype]}}(vec_b);
      temp = vmulq_{{intrin_tp_full[ctype]}}(temp, vrecpsq_{{intrin_tp_full[ctype]}}(vec_b, temp));
      return vmulq_{{intrin_tp_full[ctype]}}(vec_a, temp);
  - target_extension: "neon"
    ctype: ["uint16_t"]
    lscpu_flags: ['neon']
    is_native: False
    implementation: return vdivq_u16(vec_a, vdupq_n_u16(vec_b));
  - target_extension: "neon"
    ctype: ["uint8_t"]
    lscpu_flags: ['neon']
    is_native: False
    implementation: |
      typename Vec::register_type temp = vmol_u8(vec_a);
      temp = vmulq_n_u16(temp, 0x100);
      typename Vec::register_type result = vqrdmulhq_u8(temp, vec_b);
      result = vshrn_n_u16(result, 8);
      return result;
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: return vec_a / vec_b;
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] / vec_b[i];
      }
      return result;
...
---
primitive_name: 'mod'
brief_description: 'Operates the modulo operation on one datavector modulo one input value.'
parameters:
  - ctype: 'const typename Vec::register_type'
    name: 'vec'
    description: 'Input Vector'
  - ctype: 'const typename Vec::base_type'
    name: 'val'
    description: 'Modulo value'
returns:
  ctype: 'typename Vec::register_type'
  description: 'Resulting Vector'
testing:
  - test_name: "with_modulo_one"
    requires: ["storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      auto vec = set1<Vec>(0);
      storeu<Vec>(reference_result_ptr, vec);
      storeu<Vec>(test_result_ptr, mod<Vec>(vec, 1));
      test_helper.synchronize();
      return test_helper.validate();
  - test_name: "with_check_barrett_reduction_constraint"
    requires: [ "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      auto vec = set1<Vec>(73);
      storeu<Vec>(reference_result_ptr, set1<Vec>(1));
      auto result_vec = mod<Vec>(vec, 8);
      storeu<Vec>(test_result_ptr, result_vec);
      test_helper.synchronize();
      return test_helper.validate();
  - test_name: "with_modulo_rand"
    requires: ["loadu", "storeu"]
    implementation: |
      using T = typename Vec::base_type;
      using IntType = std::conditional_t<std::is_same_v<T, float>, int32_t, std::conditional_t<std::is_same_v<T, double>, int64_t, T>>;
      std::size_t element_count = 1024 + (1024 / Vec::vector_element_count());
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      auto offset = 1024;
      for(std::size_t i = 0; i < (element_count - offset); i +=Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(std::size_t j = i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j] % reference_data_ptr[offset];
        }
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        auto val = test_data_ptr[offset];
        auto vec_result = mod<Vec>(vec, val);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
# INTEL - AVX512
  - target_extension: 'avx512'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t' ]
    lscpu_flags: [ "avx512f" ]
    includes: [ "<array>", "<cstddef>", "<cmath>" ]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm512_store_si512(reinterpret_cast<__m512i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm512_load_si512(reinterpret_cast<__m512i const*>(buffer.data()));
  - target_extension: 'avx512'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "avx512f" ]
    includes: []
    implementation: |
      using T = float;

      __m512 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m512 val_d = _mm512_set1_ps(static_cast<T>(val));

      __m512 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_ps(temp, val_d);
      temp = _mm512_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx512'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "avx512f", "avx512dq" ]
    includes: []
    implementation: |
      using T = double;

      __m512d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m512d val_d = _mm512_set1_pd(static_cast<T>(val));

      __m512d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_pd(temp, val_d);
      temp = _mm512_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - AVX2
  - target_extension: 'avx2'
    ctype: [ 'uint8_t', 'int8_t', "uint16_t", "int16_t" ]
    lscpu_flags: [ "avx2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const*>(buffer.data()));
  - target_extension: 'avx2'
    ctype: [ 'uint32_t', 'int32_t' ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = float;

      __m256 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m256 val_d = _mm256_set1_ps(static_cast<T>(val));

      __m256 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_ps(temp, val_d);
      temp = _mm256_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx2'
    ctype: [ 'uint64_t', 'int64_t' ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = double;

      __m256d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m256d val_d = _mm256_set1_pd(static_cast<T>(val));

      __m256d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_pd(temp, val_d);
      temp = _mm256_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - SSE
  - target_extension: 'sse'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t']
    lscpu_flags: [ "sse2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm_load_si128(reinterpret_cast<__m128i const*>(buffer.data()));
  - target_extension: 'sse'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = float;
      __m128 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m128 val_d = _mm_set1_ps(static_cast<T>(val));

      __m128 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_ps(temp, val_d);
      temp = _mm_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'sse'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = double;

      __m128d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m128d val_d = _mm_set1_pd(static_cast<T>(val));

      __m128d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_pd(temp, val_d);
      temp = _mm_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# SCALAR
  - target_extension: 'scalar'
    ctype: [ 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t' ]
    lscpu_flags: [ ]
    implementation: return vec % val;
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      #pragma unroll
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec[i] % val;//vec[i] - ((vec[i] / val) * val);
      }
      return result;
...

---
primitive_name: "hmax"
brief_description: "Reduces the elements to the maximum value."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
definitions:
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
      {{ helpers.tree_like_reduce_ternary_auto("Vec", "result_vec", "data", ">") }}
      return result_vec[Vec::vector_element_count()-2];
...
---
primitive_name: "hmin"
brief_description: "Reduces the elements to the maximum value."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
definitions:
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
      {{ helpers.tree_like_reduce_ternary_auto("Vec", "result_vec", "data", "<") }}
      return result_vec[Vec::vector_element_count()-2];
...
