---
name: "calc"
description: "This file contains arithmetic primitives."
...
---
primitive_name: "add"
brief_description: "Adds two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the addition."
testing: #optional
  - test_name: "zero_cornercase"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = set1<Vec>( 0 );
        auto elements = loadu<Vec>(&test_data_ptr[i]);
        vec = add<Vec>(vec, elements);
        storeu<Vec>( test_result_ptr, vec );
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "running_sum_w_epsilon"
    requires: [ "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - 2*Vec::vector_element_count(); i+=2*Vec::vector_element_count()) {
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j]+reference_data_ptr[j+Vec::vector_element_count()];
        }
        auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
        auto elements_vec2 = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
        auto vec = add<Vec>(elements_vec1, elements_vec2);
        storeu<Vec>( test_result_ptr, vec );
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#CUDA
  - target_extension: "cuda"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ["cuda"]
    vector_length_agnostic: True
    implementation: |
      typename Vec::register_type vec_c;
      size_t element_count = VectorSize / (sizeof({{ ctype }}) * 8);
      constexpr auto add = +[]({{ ctype }} a, {{ ctype }} b) { return a + b; };
      return launch_elemenwise_op<typename Vec::register_type, add>(vec_a, vec_b, VectorSize);
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t"]
    lscpu_flags: ['avx512f', 'avx512bw']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed addition."
    implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['sse2']
    specialization_comment: "Signed addition."
    implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_add_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vaddq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: []
    implementation: "return vec_a + vec_b;"
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] + vec_b[i];
      }
      return result;
...
---
primitive_name: "sub"
brief_description: "Subtracts two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the subtraction."
testing: #optional
  - test_name: "zero_cornercase"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i+=Vec::vector_element_count()) {
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); ++j) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j];
          }
          auto vec = set1<Vec>( 0 );
          auto elements = loadu<Vec>(&test_data_ptr[i]);
          vec = sub<Vec>(elements, vec);
          storeu<Vec>( test_result_ptr, vec );
          test_helper.synchronize();
          allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "running_sum_w_epsilon"
    requires: ["loadu", "store"]
    includes: ["<cstddef>"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - 2*Vec::vector_element_count(); i+=2*Vec::vector_element_count()) {
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
            reference_result_ptr[tester_idx++] = reference_data_ptr[j]-reference_data_ptr[j+Vec::vector_element_count()];
          }
          auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
          auto elements_vec2 = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
          auto vec = sub<Vec>(elements_vec1, elements_vec2);
          storeu<Vec>( test_result_ptr, vec );
          test_helper.synchronize();
          allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#CUDA
  - target_extension: "cuda"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ["cuda"]
    vector_length_agnostic: True
    implementation: |
      typename Vec::register_type vec_c;
      size_t element_count = VectorSize / (sizeof({{ ctype }}) * 8);
      constexpr auto add = +[]({{ ctype }} a, {{ ctype }} b) { return a - b; };
      return launch_elemenwise_op<typename Vec::register_type, add>(vec_a, vec_b, VectorSize);
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t"]
    lscpu_flags: ['avx512f', 'avx512bw']
    specialization_comment: "Signed addition."
    implementation: "return _mm512_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ['avx512f']
    implementation: "return _mm512_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed addition."
    implementation: "return _mm256_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t"]
    lscpu_flags: ['sse2']
    specialization_comment: "Signed addition."
    implementation: "return _mm_sub_epi{{ intrin_tp[ctype][1] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_sub_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vsubq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: []
    implementation: "return vec_a - vec_b;"
#INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] - vec_b[i];
      }
      return result;
...
---
primitive_name: "add"
functor_name: "mask_add"
brief_description: "Adds two vector registers, depending on a mask: result[*] = (m[*])? vec_a[*]+vec_b[*] : vec_a[*]."
parameters:
  - ctype: "const typename Vec::mask_type"
    name: "mask"
    description: "Vector mask register indicating which elements should be added."
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the addition."
testing:
  - test_name: "zero_mask"
    requires: ["loadu", "storeu", "to_mask", "integral_all_false"]
    implementation: |
      using T = typename Vec::base_type;
      using reg_t = typename Vec::register_type;

      typename Vec::mask_type zero_mask = to_mask<Vec>(integral_all_false<Vec>());

      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();

      for(std::size_t i = 0; i < (element_count - Vec::vector_element_count()); i += Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
          reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        auto vec_result = add<Vec>(zero_mask, vec, vec);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "all_one_mask"
    requires: ["loadu", "storeu", "to_mask", "integral_all_true"]
    implementation: |
      using T = typename Vec::base_type;
      using reg_t = typename Vec::register_type;

      typename Vec::mask_type mask = to_mask<Vec>(integral_all_true<Vec>());

      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();

      for(std::size_t i = 0; i < (element_count - (2*Vec::vector_element_count())); i += 2*Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
          reference_result_ptr[tester_idx++] = reference_data_ptr[j] + reference_data_ptr[j + Vec::vector_element_count()];
        }
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        auto vec_b = loadu<Vec>(&test_data_ptr[i + Vec::vector_element_count()]);
        auto vec_result = add<Vec>(mask, vec_a, vec_b);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mask_add_{{ intrin_tp_full[ctype] }}(vec_a, mask, vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm256_and_si256(vec_b, mask));"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_add_{{ intrin_tp_full[ctype] }}(vec_a, _mm256_and_{{ intrin_tp_full[ctype] }}(vec_b, mask));"
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_epi{{ intrin_tp[ctype][1] }}(vec_a, _mm_and_si128(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_add_ps(vec_a, _mm_and_ps(vec_b, mask));"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_add_pd(vec_a, _mm_and_pd(vec_b, mask));"
#SCALAR
  - target_extension: "scalar"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: []
    implementation: "return (mask)? vec_a + vec_b : vec_a;"
---
primitive_name: "mul"
brief_description: "Multiplies two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the multiplication."
testing:
  - requires: ["loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        std::size_t element_count = 1024;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        for(std::size_t i = 0; i < element_count - (2*Vec::vector_element_count()); i+=(2*Vec::vector_element_count())) {
          std::size_t j = i;
          for(; j < i + Vec::vector_element_count(); ++j) {
              reference_result_ptr[j-i] = reference_data_ptr[j];
          }
          for(; j < i + (2*Vec::vector_element_count()); ++j) {
              reference_result_ptr[j-(i+Vec::vector_element_count())] *= reference_data_ptr[j];
          }
          auto vec_a = loadu<Vec>(&test_data_ptr[i]);
          auto vec_b = loadu<Vec>(&test_data_ptr[i+Vec::vector_element_count()]);
          auto vec_result = mul<Vec>(vec_a, vec_b);
          storeu<Vec>(test_result_ptr, vec_result);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
  - test_name: "multiply_by_zero"
    requires: ["loadu", "storeu", "set1"]
    includes: []
    implementation: |
      using T = typename Vec::base_type;
      using reg_t = typename Vec::register_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false };
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      reg_t vec_zero = set1<Vec>(0);
      for(std::size_t i = 0; i < (element_count - Vec::vector_element_count()); i += Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j = i; j < i + Vec::vector_element_count(); j++) {
          reference_result_ptr[tester_idx++] = 0;
        }
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        auto vec_result = mul<Vec>(vec, vec_zero);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "multiply_neg_and_neg"
    requires: ["set1", "storeu"]
    includes: []
    implementation: |
      using T = typename Vec::base_type;

      if(std::is_unsigned<T>::value){
        return true;
      }else{
        testing::test_memory_helper_t<Vec> test_helper{ Vec::vector_element_count(), false };
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();

        storeu<Vec>(reference_result_ptr, set1<Vec>(1));
        auto vec = set1<Vec>(-1);
        storeu<Vec>(test_result_ptr, mul<Vec>(vec,vec));

        test_helper.synchronize();
        return test_helper.validate();
      }
  - test_name: "multiply_neg_and_pos"
    requires: ["set1", "storeu"]
    includes: []
    implementation: |
      using T = typename Vec::base_type;

      if(std::is_unsigned<T>::value){
        return true;
      }else{
        testing::test_memory_helper_t<Vec> test_helper{ Vec::vector_element_count(), Vec::vector_element_count(), false, testing::seq_init<T>, 1 };
        auto reference_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();
        auto test_data_ptr = test_helper.data_target();
        auto reference_data_ptr = test_helper.data_ref();

        auto neg = tsl::set1<Vec>(-1);
        auto pos_ref = tsl::loadu<Vec>(reference_data_ptr);
        auto pos_target = tsl::loadu<Vec>(test_data_ptr);

        storeu<Vec>(reference_result_ptr, tsl::mul<Vec>(pos_ref, neg));
        storeu<Vec>(test_result_ptr, tsl::mul<Vec>(pos_target, neg));
        //std::cout << "========Multiply neg * pos" << tsl::type_name<Vec>() << "==================" << std::endl;
        //for (size_t i = 0; i < Vec::vector_element_count(); ++i) {
        //  std::cerr << reference_data_ptr[i] << " * -1 = " << test_result_ptr[i] << " !=?== " << reference_result_ptr[i] << std::endl;
        //}
        //std::cerr << "=======================================================" << std::endl;

        test_helper.synchronize();
        return test_helper.validate();
      }
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint16_t"]
    lscpu_flags: ["avx512bw"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["int16_t"]
    lscpu_flags: ["avx512bw"]
    implementation: "return _mm512_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi32(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi64(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
      _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_mul_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi16(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi32(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi64(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_mul_ps(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_mul_pd(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["sse2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi16(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse4_1"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi32(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi64(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= buffer_b[i];
      }
      return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vmulq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
  - target_extension: "neon"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: [ 'neon' ]
    is_native: False
    implementation: |
      return
        vsetq_lane_{{ intrin_tp_full[ctype] }}(
          vgetq_lane_{{ intrin_tp_full[ctype] }}(vec_a, 0) *
          vgetq_lane_{{ intrin_tp_full[ctype] }}(vec_b, 0),
          vmovq_n_{{ intrin_tp_full[ctype ]}}(
            vgetq_lane_{{ intrin_tp_full[ctype] }}(vec_a, 1) *
            vgetq_lane_{{ intrin_tp_full[ctype] }}(vec_b, 1)
          ),
          0
        );
      //Found this on stackoverflow. This seems like an overkill. Maybe an extract and scalar multiply would do the trick more efficient.
      //@todo: benchmark this.
      //const auto ac = vmovn_{{ intrin_tp[ctype][0] }}64(vec_a);
      //const auto pr = vmovn_{{ intrin_tp[ctype][0] }}64(vec_b);
      //const auto hi = vmulq_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_b), vrev64q_{{ intrin_tp[ctype][0] }}32(vreinterpretq_{{ intrin_tp[ctype][0] }}32_{{ intrin_tp[ctype][0] }}64(vec_a)));
      //return vmlal_{{ intrin_tp[ctype][0] }}32(vshlq_n_{{ intrin_tp[ctype][0] }}64(vpaddlq_{{ intrin_tp[ctype][0] }}32(hi), 32), ac, pr);
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: "return vec_a * vec_b;"
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] * vec_b[i];
      }
      return result;
...
---
primitive_name: "mul"
functor_name: "mul_constant"
brief_description: "Multiplies a vector register with a constant."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::base_type"
    name: "mul_var"
    description: "Multiply constant."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the multiplication."
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_mul_{{ intrin_tp_full[ctype] }}(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx512"
    ctype: ["uint16_t"]
    lscpu_flags: ["avx512bw"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi16(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx512"
    ctype: ["int16_t"]
    lscpu_flags: ["avx512bw"]
    implementation: "return _mm512_mullo_epi16(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx512"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi32(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx512"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm512_mullo_epi64(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= mul_var;
      }
      return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_mul_{{ intrin_tp_full[ctype] }}(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx2"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi16(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx2"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi32(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx2"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm256_mullo_epi64(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= mul_var;
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_mul_ps(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_mul_pd(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "sse"
    ctype: ["uint16_t", "int16_t"]
    lscpu_flags: ["sse2"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi16(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "sse"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse4_1"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi32(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "sse"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx512dq", "avx512vl"]
    specialization_comment: "Signed multiplication."
    implementation: "return _mm_mullo_epi64(vec_a, tsl::set1<Vec>(mul_var));"
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] *= mul_var;
      }
      return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: "return vec_a * mul_var;"
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] * mul_var;
      }
      return result;
...
---
primitive_name: "hadd"
brief_description: "Reduces the elements to a sum."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "value"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
testing:
  - requires: ["set1"]
    includes: ["<cstddef>", "<algorithm>", "<limits>"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{1, false};
      bool allOk = true;
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      const std::size_t limit = std::min( (size_t) 4096, (size_t) std::numeric_limits<T>::max() / Vec::vector_element_count() );
      for(std::size_t i = 0; i < limit; ++i) {
        *reference_result_ptr =  Vec::vector_element_count() * i;
        auto vec = set1<Vec>(i);
        *test_result_ptr = hadd<Vec>(vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - FPGA
  - target_extension: "oneAPIfpga"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      if constexpr(Vec::vector_element_count() < 256) {
        return reducer::apply<typename Vec::base_type, Vec::vector_element_count(), functors::add<simd<typename Vec::base_type, scalar>, Idof>>(value);
      } else {
        {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
        {{ helpers.tree_like_reduce("Vec", "result_vec", "value", "+") }}
        return result_vec[Vec::vector_element_count()-2];
      }
  - target_extension: "oneAPIfpgaRTL"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    specialization_comment: "This is for testing reasons only and does *not* use any RTL codes."
    implementation: |
      if constexpr(Vec::vector_element_count() < 256) {
        return reducer::apply<typename Vec::base_type, Vec::vector_element_count(), functors::add<simd<typename Vec::base_type, scalar>, Idof>>(value);
      } else {
        {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
        {{ helpers.tree_like_reduce("Vec", "result_vec", "value", "+") }}
        return result_vec[Vec::vector_element_count()-2];
      }
  # - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
  #   ctype: ["uint64_t", "int64_t", "double"]
  #   lscpu_flags: ["oneAPIfpgaDev"]
  #   vector_length_agnostic: True
  #   implementation: |
  #     using T = typename Vec::base_type;
  #     T result = 0; //initialize the result
  #     TSL_UNROLL(Vec::vector_element_count())
  #     for(int i = 0; i < Vec::vector_element_count(); i+=16) {
  #       T add_1_1 = value[i  ] + value[i+1];
  #       T add_1_2 = value[i+2] + value[i+3];
  #       T add_1_3 = value[i+4] + value[i+5];
  #       T add_1_4 = value[i+6] + value[i+7];

  #       T add_2_1 = add_1_1 + add_1_2;
  #       T add_2_2 = add_1_3 + add_1_4;

  #       result += add_2_1 + add_2_2;
  #     }
  #     return result;
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
    implementation: "return _mm512_reduce_add_{{ intrin_tp_full[ctype] }}(value);"
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    specialization_comment: "Signed Addition. Be aware, that this intrinsic is flagged as 'sequence' by INTEL."
    implementation: "return _mm512_reduce_add_epi{{ intrin_tp[ctype][1] }}(value);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm512_store_si512(reinterpret_cast<void*>(buffer.data()), value);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          result += buffer[i];
      }
      return result;
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["double"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      //https://stackoverflow.com/questions/49941645/get-sum-of-values-stored-in-m256d-with-sse-avx
      __m128d vlow  = _mm256_castpd256_pd128(value);
      __m128d vhigh = _mm256_extractf128_pd(value, 1);
      vlow  = _mm_add_pd(vlow, vhigh);
      __m128d high64 = _mm_unpackhi_pd(vlow, vlow);
      return  _mm_cvtsd_f64(_mm_add_sd(vlow, high64));
  - target_extension: "avx2"
    ctype: ["float"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse", "sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      __m128 vlow  = _mm256_castps256_ps128(value);
      __m128 vhigh = _mm256_extractf128_ps(value, 1);
      vlow = _mm_add_ps(vlow, vhigh);
      __m128 res = _mm_hadd_ps(vlow, vlow);
      return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
  - target_extension: "avx2"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      __m128i vlow = _mm256_castsi256_si128(value);
      __m128i vhigh = _mm256_extractf128_si256(value, 1);
      vlow = _mm_add_epi64(vlow, vhigh);
      __m128i high64 = _mm_unpackhi_epi64(vlow, vlow);
      return _mm_cvtsi128_si64(_mm_add_epi64(vlow, high64));
  - target_extension: "avx2"
    ctype: ["uint32_t", "int32_t"]
    specialization_comment: "Signed Addition. This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse2", "ssse3", "avx"]
    is_native: False
    implementation: |
      __m128i vlow = _mm256_castsi256_si128(value);
      __m128i vhigh = _mm256_extractf128_si256(value, 1);
      vlow = _mm_add_epi32(vlow, vhigh);
      __m128i res = _mm_hadd_epi32(vlow, vlow);
      return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), value);
      for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        result += buffer[i];
      }
      return result;
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    is_native: False
    implementation: |
      return _mm_cvtsd_f64(value) + _mm_cvtsd_f64(_mm_castsi128_pd(_mm_bsrli_si128(_mm_castpd_si128(value),sizeof(double))));
  - target_extension: "sse"
    ctype: ["float"]
    specialization_comment: "This instruction needs sse3. However, most intel cpus only provide ssse3 (which is a superset sse3)."
    lscpu_flags: ["sse", "sse2", "ssse3"]
    is_native: False
    implementation: |
      auto res = _mm_hadd_ps(value, value);
      return _mm_cvtss_f32(res) + _mm_cvtss_f32(_mm_castsi128_ps(_mm_bsrli_si128(_mm_castps_si128(res),sizeof(float))));
  - target_extension: "sse"
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      return _mm_cvtsi128_si64(value) + _mm_cvtsi128_si64(_mm_bsrli_si128(value,sizeof(uint64_t)));
  - target_extension: "sse"
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse2", "ssse3", "avx"]
    specialization_comment: "Signed Addition."
    is_native: False
    implementation: |
      auto res = _mm_hadd_epi32(value, value);
      return _mm_cvtsi128_si32(res) + _mm_cvtsi128_si32(_mm_bsrli_si128(res,sizeof(uint32_t)));
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      typename Vec::base_type result = 0;
      _mm_store_si128(reinterpret_cast<__m128i *>(buffer.data()), value);
      for  (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            result += buffer[i];
      }
      return result;
#ARM - NEON
  - target_extension: "neon"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: [ 'neon' ]
    implementation: "return vaddvq_{{ intrin_tp_full[ctype] }}( value );"
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: "return value;"
...
---
primitive_name: "min"
brief_description: "compares the values of 2 vectors and returns a vector with the minimum of each corrisponding values"
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector"
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector"
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the comparison"
testing:
  - test_name: "min_general_case"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        const std::size_t element_count = 2048;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        auto vec = set1<Vec>(0);
        for(std::size_t i = 0; i < element_count / 2; i += Vec::vector_element_count()){
          std::size_t tester_idx = 0;
          for(size_t j = i; j < i + Vec::vector_element_count(); j++){
            if(reference_data_ptr[j] < reference_data_ptr[j + (element_count/2)]){
              reference_result_ptr[tester_idx++] = reference_data_ptr[j];
            } else {
              reference_result_ptr[tester_idx++] = reference_data_ptr[j + (element_count/2)];
            }
          }
          auto elements_vec1 = loadu<Vec>(&test_data_ptr[i]);
          auto elements_vec2 = loadu<Vec>(&test_data_ptr[i + (element_count/2)]);
          vec = min<Vec>(elements_vec1, elements_vec2);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
  - test_name: "min_zero_case"
    requires: ["set1", "loadu", "storeu"]
    includes: ["<cstddef>"]
    implementation: |
        using T = typename Vec::base_type;
        std::size_t element_count = 1024;
        testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false};
        bool allOk = true;
        auto reference_data_ptr = test_helper.data_ref();
        auto reference_result_ptr = test_helper.result_ref();
        auto test_data_ptr = test_helper.data_target();
        auto test_result_ptr = test_helper.result_target();
        for(std::size_t i = 0; i < element_count; i += Vec::vector_element_count()){
          auto vec = set1<Vec>(0);
          storeu<Vec>(reference_result_ptr, vec);
          auto elements_vec = loadu<Vec>(&test_data_ptr[i]);
          vec = min<Vec>(vec, elements_vec);
          storeu<Vec>(test_result_ptr, vec);
          test_helper.synchronize();
          allOk &= test_helper.validate();
        }
        return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["uint32_t", "uint64_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: ['avx512f']
    specialization_comment: "Signed Min"
    implementation: "return _mm512_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "uint16_t", "int8_t", "int16_t" ]
    lscpu_flags: ['avx512bw']
    specialization_comment: "Signed Min"
    implementation: "return _mm512_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "int8_t", "int16_t", "int32_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Signed & unsigned Min"
    implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_min_{{ intrin_tp_full[ctype] }}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["int64_t", "uint64_t"]
    lscpu_flags: ['avx2']
    specialization_comment: "Takes a mask to check the smaller value of each Vector and takes that mask to get the smaller value of either vec_a or vec_b"
    is_native: False
    implementation: |
      typename Vec::register_type mask = _mm256_cmpgt_epi64(vec_a, vec_b);
      return _mm256_blendv_epi8(vec_a, vec_b, mask);
  - target_extension: ["avx2"]
    ctype: ["uint64_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      auto offset = _mm256_set1_epi64x(1ull << 63);
      auto vec_a_signed = _mm256_sub_epi64(vec_a, offset);
      auto vec_b_signed = _mm256_sub_epi64(vec_b, offset);
      auto mask = _mm256_cmpgt_epi64(vec_a_signed, vec_b_signed);
      return _mm256_blendv_epi8(vec_a, vec_b, mask);
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float"]
    lscpu_flags: ['sse']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int16_t", "double"]
    lscpu_flags: ['sse2']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["int8_t", "uint16_t", "uint32_t", "int32_t"]
    lscpu_flags: ['sse4_1']
    implementation: "return _mm_min_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["sse"]
    ctype: ["int64_t"]
    lscpu_flags: ["sse4_1", "sse4_2"]
    implementation: |
      auto mask = _mm_cmpgt_epi{{intrin_tp[ctype][1]}}(vec_a, vec_b);
      return _mm_blendv_epi8(vec_a, vec_b, mask);
  - target_extension: ["sse"]
    ctype: ["uint64_t"]
    lscpu_flags: ["sse2", "sse4_1", "sse4_2"]
    is_native: false
    implementation: |
      auto offset = _mm_set1_epi64x(1ull << 63);
      auto vec_a_signed = _mm_sub_epi64(vec_a, offset);
      auto vec_b_signed = _mm_sub_epi64(vec_b, offset);
      auto mask = _mm_cmpgt_epi64(vec_a_signed, vec_b_signed);
      return _mm_blendv_epi8(vec_a, vec_b, mask);
#ARM - NEON
  - target_extension: "neon"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "int8_t", "int32_t", "double", "float" ]
    lscpu_flags: ['neon']
    implementation: "return vminq_{{intrin_tp_full[ctype]}}(vec_a, vec_b);" #What about 64-Bit
#SCALAR
  - target_extension: "scalar"
    ctype: ["uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double"]
    lscpu_flags: []
    implementation: |
      return (vec_a < vec_b) ? vec_a : vec_b;
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] < vec_b[i] ? vec_a[i] : vec_b[i];
      }
      return result;
...
---
primitive_name: "div"
brief_description: "Divides two vector registers."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector."
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector."
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the division."
testing:
  - test_name: "vec_with_itself"
    requires: ["loadu", "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        auto vec = set1<Vec>(1);
        storeu<Vec>(reference_result_ptr, vec);
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        vec = div<Vec>(vec_a, vec_a);
        storeu<Vec>(test_result_ptr, vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "vec_with_one"
    requires: ["loadu", "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      std::size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      for(std::size_t i = 0; i < element_count - Vec::vector_element_count(); i += Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(size_t j=i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j];
        }
        auto vec = set1<Vec>(1);
        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        auto vec_result = div<Vec>(vec_a, vec);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
#INTEL - AVX512
  - target_extension: "avx512"
    ctype: ["float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "avx512"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
          alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
          _mm512_store_si512(reinterpret_cast<void*>(buffer_a.data()), vec_a);
          _mm512_store_si512(reinterpret_cast<void*>(buffer_b.data()), vec_b);
          for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
            buffer_a[i] /= buffer_b[i];
          }
          return _mm512_load_si512(reinterpret_cast<void const *>(buffer_a.data()));
#INTEL - AVX2
  - target_extension: "avx2"
    ctype: ["float", "double"]
    lscpu_flags: ['avx']
    implementation: "return _mm256_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "avx2"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['avx']
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_a.data()), vec_a);
        _mm256_store_si256(reinterpret_cast<__m256i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
           buffer_a[i] /= buffer_b[i];
        }
        return _mm256_load_si256(reinterpret_cast<__m256i const *>(buffer_a.data()));
#INTEL - SSE
  - target_extension: "sse"
    ctype: ["float", "double"]
    lscpu_flags: ['sse']
    implementation: "return _mm_div_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: "sse"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['sse2']
    is_native: False
    includes: ["<array>", "<cstddef>"]
    implementation: |
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_a;
        alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer_b;
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_a.data()), vec_a);
        _mm_store_si128(reinterpret_cast<__m128i*>(buffer_b.data()), vec_b);
        for(std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
          buffer_a[i] /= buffer_b[i];
        }
        return _mm_load_si128(reinterpret_cast<__m128i const *>(buffer_a.data()));
#ARM - NEON
  - target_extension: "neon"
    ctype: ["float", "double"]
    lscpu_flags: ['neon']
    implementation: |
      return vdivq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );
  - target_extension: "neon"
    ctype: ["uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ['neon']
    implementation: |
      {% if '32' in ctype %}
        auto float_a = tsl::cast<Vec, typename Vec::template transform_extension<float>>(vec_a);
        auto float_b = tsl::cast<Vec, typename Vec::template transform_extension<float>>(vec_b);
      {% else %}
        auto float_a = tsl::cast<Vec, typename Vec::template transform_extension<double>>(vec_a);
        auto float_b = tsl::cast<Vec, typename Vec::template transform_extension<double>>(vec_b);
      {% endif %}
      auto float_result = vdivq_f{{ intrin_tp[ctype][1] }}( float_a, float_b );
      {% if '32' in ctype %}
        return tsl::cast<typename Vec::template transform_extension<float>, Vec>(float_result);
      {% else %}
        return tsl::cast<typename Vec::template transform_extension<double>, Vec>(float_result);
      {% endif %}
  - target_extension: "neon"
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ['neon']
    implementation: |
      auto arr_a = tsl::to_array<Vec>(vec_a);
      auto arr_b = tsl::to_array<Vec>(vec_b);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        arr_a[i] /= arr_b[i];
      }
      return tsl::load<Vec>(arr_a.data());
# #ARM - NEON - TODO: Cant check if Correct
#   - target_extension: "neon"
#     ctype: ["float", "double"]
#     lscpu_flags: [ 'neon' ]
#     implementation: "return vdivq_{{ intrin_tp_full[ctype] }}( vec_a, vec_b );"
#   - target_extension: "neon"
#     ctype: ["uint64_t"]
#     lscpu_flags: ['neon']
#     implementation: |

#       typename Vec::register_type reciprocal_estimate = vshrq_n_u64(vdupq_n_u64(0xFFFFFFFFFFFFFFFF), vclzq_u64(vec_b));
#       reciprocal_estimate = vmulq_u64(reciprocal_estimate, vsubq_u64(vdupq_n_u64(2), vmulq_u64(vec_b, reciprocal_estimate)));
#       typename Vec::register_type temp = vmulq_u64(vec_a, reciprocal_estimate);
#       temp = vqrdmulhq_u64(temp, vec_b);
#       return temp;
#   - target_extension: "neon"
#     ctype: ["uint32_t"]
#     lscpu_flags: ['neon']
#     is_native: False
#     implementation: |
#       typename Vec::register_type temp = vrecpe_{{intrin_tp_full[ctype]}}(vec_b);
#       temp = vmulq_{{intrin_tp_full[ctype]}}(temp, vrecpsq_{{intrin_tp_full[ctype]}}(vec_b, temp));
#       return vmulq_{{intrin_tp_full[ctype]}}(vec_a, temp);
#   - target_extension: "neon"
#     ctype: ["uint16_t"]
#     lscpu_flags: ['neon']
#     is_native: False
#     implementation: return vdivq_u16(vec_a, vdupq_n_u16(vec_b));
#   - target_extension: "neon"
#     ctype: ["uint8_t"]
#     lscpu_flags: ['neon']
#     is_native: False
#     implementation: |
#       typename Vec::register_type temp = vmol_u8(vec_a);
#       temp = vmulq_n_u16(temp, 0x100);
#       typename Vec::register_type result = vqrdmulhq_u8(temp, vec_b);
#       result = vshrn_n_u16(result, 8);
#       return result;
#SCALAR
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t", "float", "double" ]
    lscpu_flags: [ ]
    implementation: return vec_a / vec_b;
# FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_a[i] / vec_b[i];
      }
      return result;
...
---
primitive_name: "mod"
brief_description: "Operates the modulo operation on one datavector modulo another data vector."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_data"
    description: "Input Vector"
  - ctype: "const typename Vec::register_type"
    name: "vec_mod"
    description: "Modulo Vector"
returns:
  ctype: "typename Vec::register_type"
  description: "Resulting Vector"
definitions:
# INTEL - AVX512
  - target_extension: 'avx512'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t' ]
    lscpu_flags: [ "avx512f" ]
    includes: [ "<array>", "<cstddef>", "<cmath>" ]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer1;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer2;
      _mm512_store_si512(reinterpret_cast<__m512i*>(buffer1.data()), vec_data);
      _mm512_store_si512(reinterpret_cast<__m512i*>(buffer2.data()), vec_mod);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer1[i] = buffer1[i] % buffer2[i];
      }
      return _mm512_load_si512(reinterpret_cast<__m512i const*>(buffer1.data()));
  - target_extension: 'avx512'
    ctype: [ "int32_t", "uint32_t" ]
    lscpu_flags: [ "avx512f" ]
    includes: []
    implementation: |
      using T = float;

      __m512 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m512 val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m512 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_ps(temp, val_d);
      temp = _mm512_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx512'
    ctype: [ "int64_t", "uint64_t" ]
    lscpu_flags: [ "avx512f", "avx512dq" ]
    includes: []
    implementation: |
      using T = double;

      __m512d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m512d val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m512d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_pd(temp, val_d);
      temp = _mm512_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - AVX2
  - target_extension: 'avx2'
    ctype: [ "uint8_t", "int8_t", "uint16_t", "int16_t" ]
    lscpu_flags: [ "avx2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer1;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer2;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer1.data()), vec_data);
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer2.data()), vec_mod);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer1[i] = buffer1[i] % buffer2[i];
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const*>(buffer1.data()));
  - target_extension: 'avx2'
    ctype: [ "uint32_t", "int32_t" ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = float;

      __m256 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m256 val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m256 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_ps(temp, val_d);
      temp = _mm256_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx2'
    ctype: [ "uint64_t", "int64_t" ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = double;

      __m256d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m256d val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m256d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_pd(temp, val_d);
      temp = _mm256_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - SSE
  - target_extension: 'sse'
    ctype: [ "uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: [ "sse2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer1;
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer2;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer1.data()), vec_data);
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer2.data()), vec_mod);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer1[i] = buffer1[i] % buffer2[i];
      }
      return _mm_load_si128(reinterpret_cast<__m128i const*>(buffer1.data()));
  - target_extension: 'sse'
    ctype: [ "int32_t", "uint32_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = float;
      __m128 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m128 val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m128 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_ps(temp, val_d);
      temp = _mm_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'sse'
    ctype: [ "int64_t", "uint64_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = double;

      __m128d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_data);
      __m128d val_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec_mod);

      __m128d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_pd(temp, val_d);
      temp = _mm_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: "scalar"
    ctype: [ "uint8_t", "uint16_t", "uint32_t", "uint64_t", "int8_t", "int16_t", "int32_t", "int64_t" ]
    lscpu_flags: [ ]
    implementation: return vec_data % vec_mod;
# FPGA
# we split up oneAPIfpga and oneAPIfpgaRTL just to compare the performance of the two implementations for CIDR
  - target_extension: ["oneAPIfpga"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_data[i] % vec_mod[i];
      }
      return result;
  - target_extension: ["oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec_data[i] - ((vec_data[i] / vec_mod[i]) * vec_mod[i]);
      }
      return result;
...
---
primitive_name: 'mod'
functor_name: "mod_constant"
brief_description: 'Operates the modulo operation on one datavector modulo one input value.'
parameters:
  - ctype: 'const typename Vec::register_type'
    name: 'vec'
    description: 'Input Vector'
  - ctype: 'const typename Vec::base_type'
    name: 'val'
    description: 'Modulo value'
returns:
  ctype: 'typename Vec::register_type'
  description: 'Resulting Vector'
testing:
  - test_name: "with_modulo_one"
    requires: ["storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      auto vec = set1<Vec>(0);
      storeu<Vec>(reference_result_ptr, vec);
      storeu<Vec>(test_result_ptr, mod<Vec>(vec, 1));
      test_helper.synchronize();
      return test_helper.validate();
  - test_name: "with_check_barrett_reduction_constraint"
    requires: [ "storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      auto vec = set1<Vec>(73);
      storeu<Vec>(reference_result_ptr, set1<Vec>(1));
      auto result_vec = mod<Vec>(vec, 8);
      storeu<Vec>(test_result_ptr, result_vec);
      test_helper.synchronize();
      return test_helper.validate();
  - test_name: "with_modulo_rand"
    requires: ["loadu", "storeu"]
    implementation: |
      using T = typename Vec::base_type;
      using IntType = std::conditional_t<std::is_same_v<T, float>, int32_t, std::conditional_t<std::is_same_v<T, double>, int64_t, T>>;
      std::size_t element_count = 1024 + (1024 / Vec::vector_element_count());
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      auto offset = 1024;
      for(std::size_t i = 0; i < (element_count - offset); i +=Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(std::size_t j = i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j] % reference_data_ptr[offset];
        }
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        auto val = test_data_ptr[offset];
        auto vec_result = mod<Vec>(vec, val);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
# INTEL - AVX512
  - target_extension: 'avx512'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t' ]
    lscpu_flags: [ "avx512f" ]
    includes: [ "<array>", "<cstddef>", "<cmath>" ]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm512_store_si512(reinterpret_cast<__m512i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm512_load_si512(reinterpret_cast<__m512i const*>(buffer.data()));
  - target_extension: 'avx512'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "avx512f" ]
    includes: []
    implementation: |
      using T = float;

      __m512 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m512 val_d = _mm512_set1_ps(static_cast<T>(val));

      __m512 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_ps(temp, val_d);
      temp = _mm512_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx512'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "avx512f", "avx512dq" ]
    includes: []
    implementation: |
      using T = double;

      __m512d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m512d val_d = _mm512_set1_pd(static_cast<T>(val));

      __m512d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_pd(temp, val_d);
      temp = _mm512_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - AVX2
  - target_extension: 'avx2'
    ctype: [ 'uint8_t', 'int8_t', "uint16_t", "int16_t" ]
    lscpu_flags: [ "avx2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const*>(buffer.data()));
  - target_extension: 'avx2'
    ctype: [ 'uint32_t', 'int32_t' ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = float;

      __m256 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m256 val_d = _mm256_set1_ps(static_cast<T>(val));

      __m256 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_ps(temp, val_d);
      temp = _mm256_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'avx2'
    ctype: [ 'uint64_t', 'int64_t' ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = double;

      __m256d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m256d val_d = _mm256_set1_pd(static_cast<T>(val));

      __m256d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_pd(temp, val_d);
      temp = _mm256_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - SSE
  - target_extension: 'sse'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t']
    lscpu_flags: [ "sse2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm_load_si128(reinterpret_cast<__m128i const*>(buffer.data()));
  - target_extension: 'sse'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = float;
      __m128 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m128 val_d = _mm_set1_ps(static_cast<T>(val));

      __m128 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_ps(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_ps(temp, val_d);
      temp = _mm_sub_ps(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
  - target_extension: 'sse'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = double;

      __m128d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m128d val_d = _mm_set1_pd(static_cast<T>(val));

      __m128d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_pd(temp, val_d);
      temp = _mm_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# SCALAR
  - target_extension: 'scalar'
    ctype: [ 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t' ]
    lscpu_flags: [ ]
    implementation: return vec % val;
# FPGA
# we split up oneAPIfpga and oneAPIfpgaRTL just to compare the performance of the two implementations for CIDR
  - target_extension: ["oneAPIfpga"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec[i] % val;//vec[i] - ((vec[i] / val) * val);
      }
      return result;
  - target_extension: ["oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      using T = typename Vec::register_type;
      T result; //initialize the result
      TSL_UNROLL(Vec::vector_element_count())
      for(int i = 0; i < Vec::vector_element_count(); ++i) {
        result[i] = vec[i] - ((vec[i] / val) * val);
      }
      return result;
...
---
primitive_name: 'mod_safe'
brief_description: 'Operates the modulo operation on one datavector modulo one input value.'
parameters:
  - ctype: 'const typename Vec::register_type'
    name: 'vec'
    description: 'Input Vector'
  - ctype: 'const typename Vec::base_type'
    name: 'val'
    description: 'Modulo value'
returns:
  ctype: 'typename Vec::register_type'
  description: 'Resulting Vector'
testing:
  - test_name: "with_modulo_one"
    requires: ["storeu", "set1"]
    implementation: |
      using T = typename Vec::base_type;
      testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
      auto reference_result_ptr = test_helper.result_ref();
      auto test_result_ptr = test_helper.result_target();
      auto vec = set1<Vec>(0);
      storeu<Vec>(reference_result_ptr, vec);
      storeu<Vec>(test_result_ptr, mod_safe<Vec>(vec, 1));
      test_helper.synchronize();
      return test_helper.validate();
  - test_name: "with_modulo_rand"
    requires: ["loadu", "storeu"]
    implementation: |
      using T = typename Vec::base_type;
      using IntType = std::conditional_t<std::is_same_v<T, float>, int32_t, std::conditional_t<std::is_same_v<T, double>, int64_t, T>>;
      std::size_t element_count = 1024 + (1024 / Vec::vector_element_count());
      testing::test_memory_helper_t<Vec> test_helper{element_count, Vec::vector_element_count(), false, testing::alternate_init_no_zero<T>};
      bool allOk = true;
      auto reference_data_ptr = test_helper.data_ref();
      auto reference_result_ptr = test_helper.result_ref();
      auto test_data_ptr = test_helper.data_target();
      auto test_result_ptr = test_helper.result_target();
      auto offset = 1024;
      for(std::size_t i = 0; i < (element_count - offset); i +=Vec::vector_element_count()){
        std::size_t tester_idx = 0;
        for(std::size_t j = i; j < i + Vec::vector_element_count(); j++){
          reference_result_ptr[tester_idx++] = reference_data_ptr[j] % reference_data_ptr[offset];
        }
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        auto val = test_data_ptr[offset];
        auto vec_result = mod_safe<Vec>(vec, val);
        storeu<Vec>(test_result_ptr, vec_result);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
  - test_name: "check_float_limits"
    requires: ["custom_sequence", "storeu"]
    implementation: |
      using base_t = typename Vec::base_type;
      if constexpr(!(std::is_same_v<uint32_t, base_t> || std::is_same_v<int32_t, base_t>)){
        return true;
      }else{
        testing::test_memory_helper_t<Vec> test_helper{Vec::vector_element_count(), false};
        auto ref_result_ptr = test_helper.result_ref();
        auto test_result_ptr = test_helper.result_target();

        int threshold = 16777217;
        base_t mod;
        testing::rnd_init(&mod, 1);
        auto vec = custom_sequence<Vec>(threshold);
        for(int i = 0; i < Vec::vector_element_count(); i++){
          ref_result_ptr[i] = (threshold + i) % mod;
        }
        storeu<Vec>(test_result_ptr, mod_safe<Vec>(vec, mod));
        test_helper.synchronize();
        return test_helper.validate();
      }
definitions:
# INTEL - AVX512
  - target_extension: 'avx512'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t' ]
    lscpu_flags: [ "avx512f" ]
    includes: [ "<array>", "<cstddef>", "<cmath>" ]
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm512_store_si512(reinterpret_cast<__m512i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm512_load_si512(reinterpret_cast<__m512i const*>(buffer.data()));
  - target_extension: 'avx512'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "avx512f" ]
    includes: []
    implementation: |
      using T = float;
      int threshold_value = 16777216;
      auto threshold = _mm512_set1_epi32(threshold_value);
      auto cmp_result = _mm512_cmpgt_epi32_mask(vec, threshold);
      if(cmp_result){
        auto arr = tsl::to_array<Vec>(vec);
        typename Vec::base_type result[Vec::vector_element_count()];
        for(int i = 0; i < Vec::vector_element_count(); i++){
          result[i] = arr[i] % val;
        }
        return tsl::loadu<Vec>(result);
      }else{
        __m512 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
        __m512 val_d = _mm512_set1_ps(static_cast<T>(val));

        __m512 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
        temp = _mm512_roundscale_ps(temp, _MM_FROUND_TO_ZERO);
        temp = _mm512_mul_ps(temp, val_d);
        temp = _mm512_sub_ps(vec_d, temp);

        return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
      }
  - target_extension: 'avx512'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "avx512f", "avx512dq" ]
    includes: []
    implementation: |
      using T = double;

      __m512d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m512d val_d = _mm512_set1_pd(static_cast<T>(val));

      __m512d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm512_roundscale_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm512_mul_pd(temp, val_d);
      temp = _mm512_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - AVX2
  - target_extension: 'avx2'
    ctype: [ 'uint8_t', 'int8_t', "uint16_t", "int16_t" ]
    lscpu_flags: [ "avx2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm256_store_si256(reinterpret_cast<__m256i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm256_load_si256(reinterpret_cast<__m256i const*>(buffer.data()));
  - target_extension: 'avx2'
    ctype: [ 'uint32_t', 'int32_t' ]
    lscpu_flags: [ "avx2", "avx" ]
    includes: [ ]
    implementation: |
      using T = float;
      int threshold_value = 16777216;
      auto threshold = _mm256_set1_epi32(threshold_value);
      auto cmp_result = _mm256_cmpgt_epi32(vec, threshold);
      int mask = _mm256_movemask_epi8(cmp_result);
      if(mask){
        auto arr = tsl::to_array<Vec>(vec);
        typename Vec::base_type result[Vec::vector_element_count()];
        for(int i = 0; i < Vec::vector_element_count(); i++){
          result[i] = arr[i] % val;
        }
        return tsl::loadu<Vec>(result);
      }else{
        __m256 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
        __m256 val_d = _mm256_set1_ps(static_cast<T>(val));

        __m256 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
        temp = _mm256_round_ps(temp, _MM_FROUND_TO_ZERO);
        temp = _mm256_mul_ps(temp, val_d);
        temp = _mm256_sub_ps(vec_d, temp);

        return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
      }
  - target_extension: 'avx2'
    ctype: [ 'uint64_t', 'int64_t' ]
    lscpu_flags: [ "avx2" ]
    includes: [ ]
    implementation: |
      using T = double;

      __m256d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m256d val_d = _mm256_set1_pd(static_cast<T>(val));

      __m256d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm256_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm256_mul_pd(temp, val_d);
      temp = _mm256_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# INTEL - SSE
  - target_extension: 'sse'
    ctype: [ 'uint8_t', 'int8_t', 'uint16_t', 'int16_t']
    lscpu_flags: [ "sse2" ]
    includes: ["<array>", "<cstddef>", "<cmath>"]
    is_native: false
    implementation: |
      alignas(Vec::vector_alignment()) std::array<typename Vec::base_type, Vec::vector_element_count()> buffer;
      _mm_store_si128(reinterpret_cast<__m128i*>(buffer.data()), vec);
      for (std::size_t i = 0; i < Vec::vector_element_count(); ++i) {
        buffer[i] = buffer[i] % val;
      }
      return _mm_load_si128(reinterpret_cast<__m128i const*>(buffer.data()));
  - target_extension: 'sse'
    ctype: [ 'int32_t', "uint32_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    implementation: |
      using T = float;
      int threshold_value = 16777216;
      auto threshold = _mm_set1_epi32(threshold_value);
      auto cmp_result = _mm_cmpgt_epi32(vec, threshold);
      int mask = _mm_movemask_epi8(cmp_result);
      if(mask){
        auto arr = tsl::to_array<Vec>(vec);
        typename Vec::base_type result[Vec::vector_element_count()];
        for(int i = 0; i < Vec::vector_element_count(); i++){
          result[i] = arr[i] % val;
        }
        return tsl::loadu<Vec>(result);
      }else{
        __m128 vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
        __m128 val_d = _mm_set1_ps(static_cast<T>(val));

        __m128 temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
        temp = _mm_round_ps(temp, _MM_FROUND_TO_ZERO);
        temp = _mm_mul_ps(temp, val_d);
        temp = _mm_sub_ps(vec_d, temp);

        return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
      }
  - target_extension: 'sse'
    ctype: [ 'int64_t', "uint64_t" ]
    lscpu_flags: [ "sse2", "sse4_1" ]
    includes: []
    implementation: |
      using T = double;

      __m128d vec_d = tsl::cast<Vec, typename Vec::template transform_extension<T>>(vec);
      __m128d val_d = _mm_set1_pd(static_cast<T>(val));

      __m128d temp = tsl::div<typename Vec::template transform_extension<T>>(vec_d, val_d);
      temp = _mm_round_pd(temp, _MM_FROUND_TO_ZERO);
      temp = _mm_mul_pd(temp, val_d);
      temp = _mm_sub_pd(vec_d, temp);

      return tsl::cast<typename Vec::template transform_extension<T>,Vec>(temp);
# SCALAR
  - target_extension: 'scalar'
    ctype: [ 'uint8_t', 'uint16_t', 'uint32_t', 'uint64_t', 'int8_t', 'int16_t', 'int32_t', 'int64_t' ]
    lscpu_flags: [ ]
    implementation: return vec % val;
...
---
primitive_name: "hmax"
brief_description: "Reduces the elements to the maximum value."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
testing:
  - test_name: "default"
    requires: ["loadu"]
    includes: ["<algorithm>"]
    implementation: |
      size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, 1, false};
      auto reference_result_ptr = test_helper.result_ref();
      auto reference_data_ptr = test_helper.data_ref();
      auto test_result_ptr = test_helper.result_target();
      auto test_data_ptr = test_helper.data_target();
      bool allOk = true;
      for(size_t i = 0; i < element_count; i += Vec::vector_element_count()){
        *reference_result_ptr = *std::max_element(reference_data_ptr + i, reference_data_ptr + i + Vec::vector_element_count());
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        *test_result_ptr = hmax<Vec>(vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
  #INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
      {{ helpers.tree_like_reduce_ternary_auto("Vec", "result_vec", "data", ">") }}
      return result_vec[Vec::vector_element_count()-2];
  #INTEL - AVX512
  - target_extension: ["avx512"]
    ctype: ["uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_reduce_max_{{intrin_tp_full[ctype]}}(data);"
  - target_extension: ["avx512"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::max_element(arr.begin(), arr.end());
  #INTEL - AVX2
  - target_extension: ["avx2"]
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      typename Vec::register_type y, max1, max2, max3, max4;
      y = _mm256_permute4x64_epi64(data, _MM_SHUFFLE(1, 0, 3, 2));
      max1 = _mm256_max_epi{{intrin_tp[ctype][1]}}(data, y);
      y = _mm256_shuffle_epi{{intrin_tp[ctype][1]}}(max1, _MM_SHUFFLE(1, 0, 3, 2));
      max2 = _mm256_max_epi{{intrin_tp[ctype][1]}}(max1, y);
      y = _mm256_shuffle_epi{{intrin_tp[ctype][1]}}(max2, _MM_SHUFFLE(2, 3, 0, 1));
      max3 = _mm256_max_epi{{intrin_tp[ctype][1]}}(max2, y);
      y = _mm256_permute4x64_epi64(max3, _MM_SHUFFLE(2, 3, 0, 1));
      max4 = _mm256_max_epi{{intrin_tp[ctype][1]}}(max3, y);
      return tsl::extract_value<Vec, 0>(max4);
  - target_extension: ["avx2"]
    ctype: ["float"]
    lscpu_flags: ["avx"]
    implementation: |
      typename Vec::register_type y, max1, max2, max3, max4;
      y = _mm256_permute2f128_ps(data, data, 1);
      max1 = _mm256_max_ps(data, y);
      y = _mm256_permute_ps(max1, 0b10110001);
      max2 = _mm256_max_ps(max1, y);
      y = _mm256_permute_ps(max2, 0b01001110);
      max3 = _mm256_max_ps(max2, y);
      y = _mm256_permute2f128_ps(max3, max3, 1);
      max4 = _mm256_max_ps(max3, y);
      return tsl::extract_value<Vec, 0>(max4);
  - target_extension: ["avx2"]
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      typename Vec::register_type y, max1, max2, max3;
      y = _mm256_permute4x64_epi64(data, _MM_SHUFFLE(1, 0, 3, 2));
      auto mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(data, y);
      max1 = _mm256_blendv_epi8(y, data, mask);
      y = _mm256_shuffle_epi32(max1, _MM_SHUFFLE(1, 0, 3, 2));
      mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(max1, y);
      max2 = _mm256_blendv_epi8(y, max1, mask);
      y = _mm256_permute4x64_epi64(max2, _MM_SHUFFLE(2, 3, 0, 1));
      mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(max2, y);
      max3 = _mm256_blendv_epi8(y, max2, mask);
      return tsl::extract_value<Vec, 0>(max3);
  - target_extension: ["avx2"]
    ctype: ["double"]
    lscpu_flags: ["avx"]
    implementation: |
      typename Vec::register_type y, m1, m2, m;
      y = _mm256_permute2f128_pd(data, data, 1);
      m1 = _mm256_max_pd(data, y);
      m2 = _mm256_permute_pd(m1, 5);
      m = _mm256_max_pd(m1, m2);
      return tsl::extract_value<Vec, 0>(m);
  - target_extension: ["avx2"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "double", "float"]
    lscpu_flags: ["avx2"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::max_element(arr.begin(), arr.end());
  #INTEL - SSE
  - target_extension: ["sse"]
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse2", "sse4_1"]
    implementation: |
      typename Vec::register_type max1, max2, max3, max4;
      max1 = _mm_shuffle_epi32(data, _MM_SHUFFLE(0,0,3,2));
      max2 = _mm_max_epi32(data,max1);
      max3 = _mm_shuffle_epi32(max2, _MM_SHUFFLE(0,0,0,1));
      max4 = _mm_max_epi32(max2,max3);
      return tsl::extract_value<Vec, 0>(max4);
  - target_extension: ["sse"]
    ctype: ["float"]
    lscpu_flags: ["sse", "sse2"]
    implementation: |
      typename Vec::register_type max1, max2, max3, max4;
      max1 = _mm_shuffle_ps(data, data, _MM_SHUFFLE(0,0,3,2));
      max2 = _mm_max_ps(data,max1);
      max3 = _mm_shuffle_ps(max2, max2, _MM_SHUFFLE(0,0,0,1));
      max4 = _mm_max_ps(max2,max3);
      return tsl::extract_value<Vec, 0>(max4);
  - target_extension: ["sse"]
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "see4_2", "sse4_1"]
    implementation: |
      typename Vec::register_type y, cmp, max_val;
      y = _mm_shuffle_epi32(data, _MM_SHUFFLE(1, 0, 3, 2));
      cmp = _mm_cmpgt_epi64(data, y);
      max_val = _mm_blendv_epi8(y, data, cmp);
      return tsl::extract_value<Vec, 0>(max_val);
  - target_extension: ["sse"]
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: |
      typename Vec::register_type y, max1;
      y = _mm_shuffle_{{intrin_tp_full[ctype]}}(data, data, 1);
      max1 = _mm_max_{{intrin_tp_full[ctype]}}(data, y);
      return tsl::extract_value<Vec, 0>(max1);
  - target_extension: ["sse"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::max_element(arr.begin(), arr.end());
  #SCALAR
  - target_extension: ["scalar"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: []
    implementation: return data;
...
---
primitive_name: "hmin"
brief_description: "Reduces the elements to the minimum value."
parameters:
  - ctype: "const typename Vec::register_type"
    name: "data"
    description: "Input vector."
returns:
  ctype: "typename Vec::base_type"
  description: "Scalar value after adding all elements in the vector."
testing:
  - test_name: "default"
    requires: ["loadu"]
    includes: ["<algorithm>"]
    implementation: |
      size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, 1, false};
      auto reference_result_ptr = test_helper.result_ref();
      auto reference_data_ptr = test_helper.data_ref();
      auto test_result_ptr = test_helper.result_target();
      auto test_data_ptr = test_helper.data_target();
      bool allOk = true;

      for(size_t i = 0; i < element_count; i += Vec::vector_element_count()){
        *reference_result_ptr = *std::min_element(reference_data_ptr + i, reference_data_ptr + i + Vec::vector_element_count());
        auto vec = loadu<Vec>(&test_data_ptr[i]);
        *test_result_ptr = hmin<Vec>(vec);
        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
  #INTEL - FPGA
  - target_extension: ["oneAPIfpga", "oneAPIfpgaRTL"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["oneAPIfpgaDev"]
    vector_length_agnostic: True
    implementation: |
      {% import 'core/definition_macro_helper_oneAPI.template' as helpers %}
      {{ helpers.tree_like_reduce_ternary_auto("Vec", "result_vec", "data", "<") }}
      return result_vec[Vec::vector_element_count()-2];
  #INTEL - AVX512
  - target_extension: ["avx512"]
    ctype: ["uint32_t", "int32_t", "uint64_t", "int64_t", "float", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_reduce_min_{{intrin_tp_full[ctype]}}(data);"
  - target_extension: ["avx512"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["avx512f"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::min_element(arr.begin(), arr.end());
  #INTEL - AVX2
  - target_extension: ["avx2"]
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      typename Vec::register_type y, min1, min2, min3, min4;
      y = _mm256_permute4x64_epi64(data, _MM_SHUFFLE(1, 0, 3, 2));
      min1 = _mm256_min_epi{{intrin_tp[ctype][1]}}(data, y);
      y = _mm256_shuffle_epi{{intrin_tp[ctype][1]}}(min1, _MM_SHUFFLE(1, 0, 3, 2));
      min2 = _mm256_min_epi{{intrin_tp[ctype][1]}}(min1, y);
      y = _mm256_shuffle_epi{{intrin_tp[ctype][1]}}(min2, _MM_SHUFFLE(2, 3, 0, 1));
      min3 = _mm256_min_epi{{intrin_tp[ctype][1]}}(min2, y);
      y = _mm256_permute4x64_epi64(min3, _MM_SHUFFLE(2, 3, 0, 1));
      min4 = _mm256_min_epi{{intrin_tp[ctype][1]}}(min3, y);
      return tsl::extract_value<Vec, 0>(min4);
  - target_extension: ["avx2"]
    ctype: ["float"]
    lscpu_flags: ["avx"]
    implementation: |
      typename Vec::register_type y, min1, min2, min3, min4;
      y = _mm256_permute2f128_ps(data, data, 1);
      min1 = _mm256_min_ps(data, y);
      y = _mm256_permute_ps(min1, 0b10110001);
      min2 = _mm256_min_ps(min1, y);
      y = _mm256_permute_ps(min2, 0b01001110);
      min3 = _mm256_min_ps(min2, y);
      y = _mm256_permute2f128_ps(min3, min3, 1);
      min4 = _mm256_min_ps(min3, y);
      return tsl::extract_value<Vec, 0>(min4);
  - target_extension: ["avx2"]
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      typename Vec::register_type y, min1, min2, min3;
      y = _mm256_permute4x64_epi64(data, _MM_SHUFFLE(1, 0, 3, 2));
      auto mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(y, data);
      min1 = _mm256_blendv_epi8(y, data, mask);
      y = _mm256_shuffle_epi32(min1, _MM_SHUFFLE(1, 0, 3, 2));
      mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(y, min1);
      min2 = _mm256_blendv_epi8(y, min1, mask);
      y = _mm256_permute4x64_epi64(min2, _MM_SHUFFLE(2, 3, 0, 1));
      mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(y, min2);
      min3 = _mm256_blendv_epi8(y, min2, mask);
      return tsl::extract_value<Vec, 0>(min3);
  - target_extension: ["avx2"]
    ctype: ["double"]
    lscpu_flags: ["avx"]
    implementation: |
      typename Vec::register_type y, m1, m2, m;
      y = _mm256_permute2f128_pd(data, data, 1);
      m1 = _mm256_min_pd(data, y);
      m2 = _mm256_permute_pd(m1, 5);
      m = _mm256_min_pd(m1, m2);
      return tsl::extract_value<Vec, 0>(m);
  - target_extension: ["avx2"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "uint64_t", "int64_t", "double", "float"]
    lscpu_flags: ["avx2"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::min_element(arr.begin(), arr.end());
  #INTEL - SSE
  - target_extension: ["sse"]
    ctype: ["uint32_t", "int32_t"]
    lscpu_flags: ["sse2", "sse4_1"]
    implementation: |
      typename Vec::register_type min1, min2, min3, min4;
      min1 = _mm_shuffle_epi32(data, _MM_SHUFFLE(0,0,3,2));
      min2 = _mm_min_epi32(data,min1);
      min3 = _mm_shuffle_epi32(min2, _MM_SHUFFLE(0,0,0,1));
      min4 = _mm_min_epi32(min2,min3);
      return tsl::extract_value<Vec, 0>(min4);
  - target_extension: ["sse"]
    ctype: ["float"]
    lscpu_flags: ["sse", "sse2"]
    implementation: |
      typename Vec::register_type min1, min2, min3, min4;
      min1 = _mm_shuffle_ps(data, data, _MM_SHUFFLE(0,0,3,2));
      min2 = _mm_min_ps(data,min1);
      min3 = _mm_shuffle_ps(min2, min2, _MM_SHUFFLE(0,0,0,1));
      min4 = _mm_min_ps(min2,min3);
      return tsl::extract_value<Vec, 0>(min4);
  - target_extension: ["sse"]
    ctype: ["uint64_t", "int64_t"]
    lscpu_flags: ["sse2", "see4_2", "sse4_1"]
    implementation: |
      typename Vec::register_type y, cmp, min_val;
      y = _mm_shuffle_epi32(data, _MM_SHUFFLE(1, 0, 3, 2));
      cmp = _mm_cmpgt_epi64(data, y);
      min_val = _mm_blendv_epi8(y, data, cmp);
      return tsl::extract_value<Vec, 0>(min_val);
  - target_extension: ["sse"]
    ctype: ["double"]
    lscpu_flags: ["sse2"]
    implementation: |
      typename Vec::register_type y, min1;
      y = _mm_shuffle_{{intrin_tp_full[ctype]}}(data, data, 1);
      min1 = _mm_min_{{intrin_tp_full[ctype]}}(data, y);
      return tsl::extract_value<Vec, 0>(min1);
  - target_extension: ["sse"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["sse2"]
    is_native: False
    includes: ["<algorithm>"]
    implementation: |
      auto arr = tsl::to_array<Vec>(data);
      return *std::min_element(arr.begin(), arr.end());
  #SCALAR
  - target_extension: ["scalar"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: []
    implementation: return data;
...
---
primitive_name: "max"
brief_description: "compares the values of 2 vectors and returns a vector with the maximum of each corrisponding values"
parameters:
  - ctype: "const typename Vec::register_type"
    name: "vec_a"
    description: "First vector"
  - ctype: "const typename Vec::register_type"
    name: "vec_b"
    description: "Second vector"
returns:
  ctype: "typename Vec::register_type"
  description: "Vector containing result of the comparison"
testing:
  - test_name: "default"
    requires: ["loadu", "storeu"]
    implementation: |
      using base_t = typename Vec::base_type;
      using reg_t = typename Vec::register_type;
      auto vec_count = Vec::vector_element_count();
      size_t element_count = 1024;
      testing::test_memory_helper_t<Vec> test_helper{element_count, vec_count, false};
      auto reference_result_ptr = test_helper.result_ref();
      auto reference_data_ptr = test_helper.data_ref();
      auto test_result_ptr = test_helper.result_target();
      auto test_data_ptr = test_helper.data_target();
      bool allOk = true;

      for(size_t i = 0; i < element_count; i += 2*vec_count){
        base_t arr[vec_count];
        for(size_t j = 0; j < vec_count; j++){
          (reference_data_ptr[i+j] < reference_data_ptr[i+j+vec_count]) ? arr[j] = reference_data_ptr[i+j+vec_count] : arr[j] = reference_data_ptr[i+j];
        }
        auto ref_result = loadu<Vec>(arr);

        auto vec_a = loadu<Vec>(&test_data_ptr[i]);
        auto vec_b = loadu<Vec>(&test_data_ptr[i+vec_count]);
        auto result = max<Vec>(vec_a, vec_b);

        storeu<Vec>(test_result_ptr, result);
        storeu<Vec>(reference_result_ptr, ref_result);

        test_helper.synchronize();
        allOk &= test_helper.validate();
      }
      return allOk;
definitions:
  # INTEL - AVX512
  - target_extension: ["avx512"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t"]
    lscpu_flags: ["avx512bw"]
    implementation: "return _mm512_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["avx512"]
    ctype: ["uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["avx512f"]
    implementation: "return _mm512_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  # INTEL - AVX2
  - target_extension: ["avx2"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t"]
    lscpu_flags: ["avx2"]
    implementation: "return _mm256_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["avx2"]
    ctype: ["float", "double"]
    lscpu_flags: ["avx"]
    implementation: "return _mm256_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["avx2"]
    ctype: ["int64_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      auto mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(vec_a, vec_b);
      return _mm256_blendv_epi8(vec_b, vec_a, mask);
  - target_extension: ["avx2"]
    ctype: ["uint64_t"]
    lscpu_flags: ["avx2"]
    implementation: |
      auto offset = _mm256_set1_epi64x(1ull << 63);
      auto vec_a_signed = _mm256_sub_epi64(vec_a, offset);
      auto vec_b_signed = _mm256_sub_epi64(vec_b, offset);
      auto mask = _mm256_cmpgt_epi{{intrin_tp[ctype][1]}}(vec_a_signed, vec_b_signed);
      return _mm256_blendv_epi8(vec_b, vec_a, mask);
  - target_extension: ["avx2"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["avx2", "avx"]
    is_native: False
    implementation: |
      auto arr_a = tsl::to_array<Vec>(vec_a);
      auto arr_b = tsl::to_array<Vec>(vec_b);
      typename Vec::base_type result[Vec::vector_element_count()];
      for(size_t i = 0; i < Vec::vector_element_count(); i++){
        (arr_a[i] < arr_b [i]) ? result[i] = arr_b[i] : result[i] = arr_a[i];
      }
      return tsl::loadu<Vec>(result);
  # INTEL - SSE
  - target_extension: ["sse"]
    ctype: ["int16_t", "uint8_t", "double"]
    lscpu_flags: ["sse2"]
    implementation: "return _mm_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["sse"]
    ctype: ["float"]
    lscpu_flags: ["sse"]
    implementation: "return _mm_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["sse"]
    ctype: ["int32_t", "int8_t", "uint16_t", "uint32_t"]
    lscpu_flags: ["sse4_1"]
    implementation: "return _mm_max_{{intrin_tp_full[ctype]}}(vec_a, vec_b);"
  - target_extension: ["sse"]
    ctype: ["int64_t"]
    lscpu_flags: ["sse4_1", "sse4_2"]
    implementation: |
      auto mask = _mm_cmpgt_epi{{intrin_tp[ctype][1]}}(vec_a, vec_b);
      return _mm_blendv_epi8(vec_b, vec_a, mask);
  - target_extension: ["sse"]
    ctype: ["uint64_t"]
    lscpu_flags: ["sse2", "sse4_1", "sse4_2"]
    implementation: |
      auto offset = _mm_set1_epi64x(1ull << 63);
      auto vec_a_signed = _mm_sub_epi64(vec_a, offset);
      auto vec_b_signed = _mm_sub_epi64(vec_b, offset);
      auto mask = _mm_cmpgt_epi64(vec_a_signed, vec_b_signed);
      return _mm_blendv_epi8(vec_b, vec_a, mask);
  - target_extension: ["sse"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: ["sse", "sse2"]
    is_native: False
    implementation: |
      auto arr_a = tsl::to_array<Vec>(vec_a);
      auto arr_b = tsl::to_array<Vec>(vec_b);
      typename Vec::base_type result[Vec::vector_element_count()];
      for(size_t i = 0; i < Vec::vector_element_count(); i++){
        (arr_a[i] < arr_b [i]) ? result[i] = arr_b[i] : result[i] = arr_a[i];
      }
      return tsl::loadu<Vec>(result);
  # SCALAR
  - target_extension: ["scalar"]
    ctype: ["uint8_t", "int8_t", "uint16_t", "int16_t", "uint32_t", "int32_t", "float", "uint64_t", "int64_t", "double"]
    lscpu_flags: []
    implementation: "return (vec_a > vec_b) ? vec_a : vec_b;"
...
